# Debug configuration for testing datahub stuff
defaults:
  - debug

dataloader:
  DATAHUB_MODE: DATAHUB
  DATAPKL_AA: aa_dataset_256_subsampled_10.pkl
  CROP: 60

datahub:
  test_dhub_dataset:
    probability: 1.0
    dataset:
      _target_: datahub.datasets.datasets.StructuralDatasetWrapper
      save_failed_examples_to_dir: null
      cif_parser_args:
        load_from_cache: False
        save_to_cache: False
      dataset_parser:
        _target_: rf_diffusion.datahub_dataset_interface.SimplePathParser
      dataset:
        _target_: datahub.datasets.datasets.PandasDataset
        name: debug_dataset
        id_column: example_id
        data: test_data/test_dataset/test_dataset.parquet
        filters:
          - "cluster.notnull()"
        columns_to_load:
          # columns required for identification, filtering & weighting
          - example_id
          - cluster
          - path
      transform:
        _target_: rf_diffusion.datahub_pipelines.rf_diffusion.build_rf_diffusion_transform_pipeline
        crop_size: 3000
        crop_contiguous_probability: 0.9
        crop_spatial_probability: 0.1
    weights:
      _target_: datahub.samplers.calculate_weights_by_inverse_cluster_size



